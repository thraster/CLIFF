{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " procrustes_3d进行对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: 句柄无效。 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def procrustes_3d(X, Y):\n",
    "    \"\"\"\n",
    "    Perform Procrustes alignment of 3D points.\n",
    "    \n",
    "    Args:\n",
    "    - X (np.array): Source points, shape (N, 3)\n",
    "    - Y (np.array): Target points, shape (N, 3)\n",
    "    \n",
    "    Returns:\n",
    "    - Z (np.array): Aligned source points, shape (N, 3)\n",
    "    \"\"\"\n",
    "    # Translate X and Y to their centroids\n",
    "    X_centroid = X.mean(axis=0)\n",
    "    Y_centroid = Y.mean(axis=0)\n",
    "    X = X - X_centroid\n",
    "    Y = Y - Y_centroid\n",
    "    \n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = np.dot(Y.T, X)\n",
    "    \n",
    "    # Singular Value Decomposition\n",
    "    U, S, Vt = np.linalg.svd(covariance_matrix)\n",
    "    \n",
    "    # Compute the rotation matrix\n",
    "    R = np.dot(U, Vt)\n",
    "    \n",
    "    # Apply the rotation to X\n",
    "    Z = np.dot(X, R)\n",
    "    \n",
    "    # Scale the points\n",
    "    scale = np.trace(np.dot(Z.T, Y)) / np.trace(np.dot(Z.T, Z))\n",
    "    Z *= scale\n",
    "    \n",
    "    # Translate back to the target's centroid\n",
    "    Z += Y_centroid\n",
    "    \n",
    "    return Z\n",
    "import open3d as o3d\n",
    "\n",
    "def visualize_3d_joints_open3d(pred_joints, gt_joints, aligned_joints):\n",
    "    \"\"\"\n",
    "    Visualize 3D joints before and after Procrustes alignment using Open3D.\n",
    "    \n",
    "    Args:\n",
    "    - pred_joints (np.array): Predicted joint positions, shape (K, 3)\n",
    "    - gt_joints (np.array): Ground truth joint positions, shape (K, 3)\n",
    "    - aligned_joints (np.array): Aligned predicted joint positions, shape (K, 3)\n",
    "    \"\"\"\n",
    "    # Create Open3D point clouds\n",
    "    pred_pcd = o3d.geometry.PointCloud()\n",
    "    gt_pcd = o3d.geometry.PointCloud()\n",
    "    aligned_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    pred_pcd.points = o3d.utility.Vector3dVector(pred_joints)\n",
    "    gt_pcd.points = o3d.utility.Vector3dVector(gt_joints)\n",
    "    aligned_pcd.points = o3d.utility.Vector3dVector(aligned_joints)\n",
    "    \n",
    "    # Set colors for visualization\n",
    "    pred_pcd.paint_uniform_color([1, 0, 0])  # Red\n",
    "    gt_pcd.paint_uniform_color([0, 1, 0])    # Green\n",
    "    aligned_pcd.paint_uniform_color([0, 0, 1])  # Blue\n",
    "    \n",
    "    # Visualize the point clouds\n",
    "    o3d.visualization.draw_geometries([pred_pcd, gt_pcd, aligned_pcd])\n",
    "\n",
    "\n",
    "\n",
    "data_gt = np.load(r'E:\\WorkSpace\\inbed_pose_repos\\CLIFF\\slp_sample\\p102.npz')\n",
    "data_pred = np.load(r'E:\\WorkSpace\\inbed_pose_repos\\CLIFF\\slp_sample\\cliff_2djoint.npz')\n",
    "\n",
    "# Example usage for a single sample:\n",
    "pred_joints_sample = data_pred['pred_joints'][0, :24, :]\n",
    "gt_joints_sample = data_gt['gt_3D_joints'][0]\n",
    "\n",
    "# Perform Procrustes alignment\n",
    "aligned_pred_joints_sample = procrustes_3d(pred_joints_sample, gt_joints_sample)\n",
    "\n",
    "# Visualize the joints\n",
    "visualize_3d_joints_open3d(pred_joints_sample, gt_joints_sample, aligned_pred_joints_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_compute_similarity_transform_torch(S1, S2):\n",
    "    '''\n",
    "    Computes a similarity transform (sR, t) that takes\n",
    "    a set of 3D points S1 (3 x N) closest to a set of 3D points S2,\n",
    "    where R is an 3x3 rotation matrix, t 3x1 translation, s scale.\n",
    "    i.e. solves the orthogonal Procrutes problem.\n",
    "    '''\n",
    "    transposed = False\n",
    "    if S1.shape[0] != 3 and S1.shape[0] != 2:\n",
    "        S1 = S1.permute(0,2,1)\n",
    "        S2 = S2.permute(0,2,1)\n",
    "        transposed = True\n",
    "    assert(S2.shape[1] == S1.shape[1])\n",
    "\n",
    "    # 1. Remove mean.\n",
    "    mu1 = S1.mean(axis=-1, keepdims=True)\n",
    "    mu2 = S2.mean(axis=-1, keepdims=True)\n",
    "\n",
    "    X1 = S1 - mu1\n",
    "    X2 = S2 - mu2\n",
    "\n",
    "    # 2. Compute variance of X1 used for scale.\n",
    "    var1 = torch.sum(X1**2, dim=1).sum(dim=1)\n",
    "\n",
    "    # 3. The outer product of X1 and X2.\n",
    "    K = X1.bmm(X2.permute(0,2,1))\n",
    "\n",
    "    # 4. Solution that Maximizes trace(R'K) is R=U*V', where U, V are\n",
    "    # singular vectors of K.\n",
    "    U, s, V = torch.svd(K)\n",
    "\n",
    "    # Construct Z that fixes the orientation of R to get det(R)=1.\n",
    "    Z = torch.eye(U.shape[1], device=S1.device).unsqueeze(0)\n",
    "    Z = Z.repeat(U.shape[0],1,1)\n",
    "    Z[:,-1, -1] *= torch.sign(torch.det(U.bmm(V.permute(0,2,1))))\n",
    "\n",
    "    # Construct R.\n",
    "    R = V.bmm(Z.bmm(U.permute(0,2,1)))\n",
    "\n",
    "    # 5. Recover scale.\n",
    "    scale = torch.cat([torch.trace(x).unsqueeze(0) for x in R.bmm(K)]) / var1\n",
    "\n",
    "    # 6. Recover translation.\n",
    "    t = mu2 - (scale.unsqueeze(-1).unsqueeze(-1) * (R.bmm(mu1)))\n",
    "\n",
    "    # 7. Error:\n",
    "    S1_hat = scale.unsqueeze(-1).unsqueeze(-1) * R.bmm(S1) + t\n",
    "\n",
    "    if transposed:\n",
    "        S1_hat = S1_hat.permute(0,2,1)\n",
    "\n",
    "    return S1_hat, (scale, R, t)\n",
    "\n",
    "\n",
    "def visualize_3d_joints_open3d(pred_joints, gt_joints, aligned_joints):\n",
    "    \"\"\"\n",
    "    Visualize 3D joints before and after Procrustes alignment using Open3D.\n",
    "    \n",
    "    Args:\n",
    "    - pred_joints (np.array): Predicted joint positions, shape (K, 3)\n",
    "    - gt_joints (np.array): Ground truth joint positions, shape (K, 3)\n",
    "    - aligned_joints (np.array): Aligned predicted joint positions, shape (K, 3)\n",
    "    \"\"\"\n",
    "    # Ensure inputs are in the right shape and type\n",
    "    pred_joints = np.asarray(pred_joints)\n",
    "    gt_joints = np.asarray(gt_joints)\n",
    "    aligned_joints = np.asarray(aligned_joints)\n",
    "    \n",
    "    # Create Open3D point clouds\n",
    "    pred_pcd = o3d.geometry.PointCloud()\n",
    "    gt_pcd = o3d.geometry.PointCloud()\n",
    "    aligned_pcd = o3d.geometry.PointCloud()\n",
    "    \n",
    "    pred_pcd.points = o3d.utility.Vector3dVector(pred_joints)\n",
    "    gt_pcd.points = o3d.utility.Vector3dVector(gt_joints)\n",
    "    aligned_pcd.points = o3d.utility.Vector3dVector(aligned_joints)\n",
    "    \n",
    "    # Set colors for visualization\n",
    "    pred_pcd.paint_uniform_color([1, 0, 0])  # Red\n",
    "    gt_pcd.paint_uniform_color([0, 1, 0])    # Green\n",
    "    aligned_pcd.paint_uniform_color([0, 0, 1])  # Blue\n",
    "    \n",
    "    # Visualize the point clouds\n",
    "    o3d.visualization.draw_geometries([pred_pcd, gt_pcd, aligned_pcd])\n",
    "\n",
    "\n",
    "data_gt = np.load(r'E:\\WorkSpace\\inbed_pose_repos\\CLIFF\\slp_sample\\p102.npz')\n",
    "data_pred = np.load(r'E:\\WorkSpace\\inbed_pose_repos\\CLIFF\\slp_sample\\cliff_2djoint.npz')\n",
    "\n",
    "# Example usage for a single sample:\n",
    "pred_joints_sample = torch.from_numpy(data_pred['pred_joints'][:, :24, :])\n",
    "gt_joints_sample = torch.from_numpy(data_gt['gt_3D_joints'])\n",
    "\n",
    "# Perform Procrustes alignment\n",
    "aligned_pred_joints,_ = batch_compute_similarity_transform_torch(pred_joints_sample, gt_joints_sample)\n",
    "\n",
    "i = 1\n",
    "\n",
    "\n",
    "# Example usage for a single sample:\n",
    "pred_joints_sample = data_pred['pred_joints'][i, :24, :]\n",
    "gt_joints_sample = data_gt['gt_3D_joints'][i]\n",
    "\n",
    "# Perform Procrustes alignment\n",
    "aligned_pred_joints_sample = procrustes_3d(pred_joints_sample, gt_joints_sample)\n",
    "\n",
    "# Visualize the joints\n",
    "visualize_3d_joints_open3d(pred_joints_sample, aligned_pred_joints_sample, aligned_pred_joints[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
