digraph {
	graph [size="186.9,186.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2504708533920 [label="
 (1, 24, 3, 3)" fillcolor=darkolivegreen1]
	2504708489168 [label=ViewBackward0]
	2504708488736 -> 2504708489168
	2504708488736 [label=StackBackward0]
	2504708489072 -> 2504708488736
	2504708489072 [label=DivBackward0]
	2504708488592 -> 2504708489072
	2504708488592 [label=SelectBackward0]
	2504708488352 -> 2504708488592
	2504708488352 [label=SliceBackward0]
	2504708488256 -> 2504708488352
	2504708488256 [label=SliceBackward0]
	2504708488112 -> 2504708488256
	2504708488112 [label=ViewBackward0]
	2504869875040 -> 2504708488112
	2504869875040 [label=AddBackward0]
	2504708488544 -> 2504869875040
	2504708488544 [label=AddmmBackward0]
	2504708563200 -> 2504708488544
	2504749335872 [label="decpose.bias
 (144)" fillcolor=lightblue]
	2504749335872 -> 2504708563200
	2504708563200 [label=AccumulateGrad]
	2504708563152 -> 2504708488544
	2504708563152 [label=MulBackward0]
	2504708563296 -> 2504708563152
	2504708563296 [label=AddmmBackward0]
	2504708563488 -> 2504708563296
	2504749335712 [label="fc2.bias
 (1024)" fillcolor=lightblue]
	2504749335712 -> 2504708563488
	2504708563488 [label=AccumulateGrad]
	2504708563440 -> 2504708563296
	2504708563440 [label=MulBackward0]
	2504708563584 -> 2504708563440
	2504708563584 [label=AddmmBackward0]
	2504708563776 -> 2504708563584
	2504749335552 [label="fc1.bias
 (1024)" fillcolor=lightblue]
	2504749335552 -> 2504708563776
	2504708563776 [label=AccumulateGrad]
	2504708563728 -> 2504708563584
	2504708563728 [label=CatBackward0]
	2504708563872 -> 2504708563728
	2504708563872 [label=ViewBackward0]
	2504708564160 -> 2504708563872
	2504708564160 [label=AvgPool2DBackward0]
	2504708564256 -> 2504708564160
	2504708564256 [label=ReluBackward0]
	2504708564352 -> 2504708564256
	2504708564352 [label=AddBackward0]
	2504708564448 -> 2504708564352
	2504708564448 [label=NativeBatchNormBackward0]
	2504708564592 -> 2504708564448
	2504708564592 [label=ConvolutionBackward0]
	2504708564784 -> 2504708564592
	2504708564784 [label=ReluBackward0]
	2504708564928 -> 2504708564784
	2504708564928 [label=NativeBatchNormBackward0]
	2504708565024 -> 2504708564928
	2504708565024 [label=ConvolutionBackward0]
	2504708565216 -> 2504708565024
	2504708565216 [label=ReluBackward0]
	2504708565360 -> 2504708565216
	2504708565360 [label=NativeBatchNormBackward0]
	2504708565456 -> 2504708565360
	2504708565456 [label=ConvolutionBackward0]
	2504708564400 -> 2504708565456
	2504708564400 [label=ReluBackward0]
	2504708565744 -> 2504708564400
	2504708565744 [label=AddBackward0]
	2504708565840 -> 2504708565744
	2504708565840 [label=NativeBatchNormBackward0]
	2504708565984 -> 2504708565840
	2504708565984 [label=ConvolutionBackward0]
	2504708566176 -> 2504708565984
	2504708566176 [label=ReluBackward0]
	2504708566320 -> 2504708566176
	2504708566320 [label=NativeBatchNormBackward0]
	2504708566416 -> 2504708566320
	2504708566416 [label=ConvolutionBackward0]
	2504708566608 -> 2504708566416
	2504708566608 [label=ReluBackward0]
	2504708566752 -> 2504708566608
	2504708566752 [label=NativeBatchNormBackward0]
	2504708566848 -> 2504708566752
	2504708566848 [label=ConvolutionBackward0]
	2504708565792 -> 2504708566848
	2504708565792 [label=ReluBackward0]
	2504708575392 -> 2504708565792
	2504708575392 [label=AddBackward0]
	2504708575488 -> 2504708575392
	2504708575488 [label=NativeBatchNormBackward0]
	2504708575632 -> 2504708575488
	2504708575632 [label=ConvolutionBackward0]
	2504708575824 -> 2504708575632
	2504708575824 [label=ReluBackward0]
	2504708575968 -> 2504708575824
	2504708575968 [label=NativeBatchNormBackward0]
	2504708576064 -> 2504708575968
	2504708576064 [label=ConvolutionBackward0]
	2504708576256 -> 2504708576064
	2504708576256 [label=ReluBackward0]
	2504708576400 -> 2504708576256
	2504708576400 [label=NativeBatchNormBackward0]
	2504708576496 -> 2504708576400
	2504708576496 [label=ConvolutionBackward0]
	2504708576688 -> 2504708576496
	2504708576688 [label=ReluBackward0]
	2504708576832 -> 2504708576688
	2504708576832 [label=AddBackward0]
	2504708576928 -> 2504708576832
	2504708576928 [label=NativeBatchNormBackward0]
	2504708577072 -> 2504708576928
	2504708577072 [label=ConvolutionBackward0]
	2504708577264 -> 2504708577072
	2504708577264 [label=ReluBackward0]
	2504708577408 -> 2504708577264
	2504708577408 [label=NativeBatchNormBackward0]
	2504708577504 -> 2504708577408
	2504708577504 [label=ConvolutionBackward0]
	2504708577696 -> 2504708577504
	2504708577696 [label=ReluBackward0]
	2504708577840 -> 2504708577696
	2504708577840 [label=NativeBatchNormBackward0]
	2504708577936 -> 2504708577840
	2504708577936 [label=ConvolutionBackward0]
	2504708576880 -> 2504708577936
	2504708576880 [label=ReluBackward0]
	2504708578224 -> 2504708576880
	2504708578224 [label=AddBackward0]
	2504708578320 -> 2504708578224
	2504708578320 [label=NativeBatchNormBackward0]
	2504708578464 -> 2504708578320
	2504708578464 [label=ConvolutionBackward0]
	2504708578656 -> 2504708578464
	2504708578656 [label=ReluBackward0]
	2504708578800 -> 2504708578656
	2504708578800 [label=NativeBatchNormBackward0]
	2504708578896 -> 2504708578800
	2504708578896 [label=ConvolutionBackward0]
	2504708579088 -> 2504708578896
	2504708579088 [label=ReluBackward0]
	2504708579232 -> 2504708579088
	2504708579232 [label=NativeBatchNormBackward0]
	2504708579280 -> 2504708579232
	2504708579280 [label=ConvolutionBackward0]
	2504708578272 -> 2504708579280
	2504708578272 [label=ReluBackward0]
	2504708591968 -> 2504708578272
	2504708591968 [label=AddBackward0]
	2504708592016 -> 2504708591968
	2504708592016 [label=NativeBatchNormBackward0]
	2504708592256 -> 2504708592016
	2504708592256 [label=ConvolutionBackward0]
	2504708592448 -> 2504708592256
	2504708592448 [label=ReluBackward0]
	2504708592592 -> 2504708592448
	2504708592592 [label=NativeBatchNormBackward0]
	2504708592640 -> 2504708592592
	2504708592640 [label=ConvolutionBackward0]
	2504708592928 -> 2504708592640
	2504708592928 [label=ReluBackward0]
	2504708593072 -> 2504708592928
	2504708593072 [label=NativeBatchNormBackward0]
	2504708593120 -> 2504708593072
	2504708593120 [label=ConvolutionBackward0]
	2504708591776 -> 2504708593120
	2504708591776 [label=ReluBackward0]
	2504708593504 -> 2504708591776
	2504708593504 [label=AddBackward0]
	2504708593552 -> 2504708593504
	2504708593552 [label=NativeBatchNormBackward0]
	2504708593792 -> 2504708593552
	2504708593792 [label=ConvolutionBackward0]
	2504708593984 -> 2504708593792
	2504708593984 [label=ReluBackward0]
	2504708594128 -> 2504708593984
	2504708594128 [label=NativeBatchNormBackward0]
	2504708594176 -> 2504708594128
	2504708594176 [label=ConvolutionBackward0]
	2504708594464 -> 2504708594176
	2504708594464 [label=ReluBackward0]
	2504708594608 -> 2504708594464
	2504708594608 [label=NativeBatchNormBackward0]
	2504708594656 -> 2504708594608
	2504708594656 [label=ConvolutionBackward0]
	2504708593312 -> 2504708594656
	2504708593312 [label=ReluBackward0]
	2504708595040 -> 2504708593312
	2504708595040 [label=AddBackward0]
	2504708595088 -> 2504708595040
	2504708595088 [label=NativeBatchNormBackward0]
	2504708595328 -> 2504708595088
	2504708595328 [label=ConvolutionBackward0]
	2504708595520 -> 2504708595328
	2504708595520 [label=ReluBackward0]
	2504708595664 -> 2504708595520
	2504708595664 [label=NativeBatchNormBackward0]
	2504708604016 -> 2504708595664
	2504708604016 [label=ConvolutionBackward0]
	2504708604256 -> 2504708604016
	2504708604256 [label=ReluBackward0]
	2504708604400 -> 2504708604256
	2504708604400 [label=NativeBatchNormBackward0]
	2504708604448 -> 2504708604400
	2504708604448 [label=ConvolutionBackward0]
	2504708594848 -> 2504708604448
	2504708594848 [label=ReluBackward0]
	2504708604832 -> 2504708594848
	2504708604832 [label=AddBackward0]
	2504708604880 -> 2504708604832
	2504708604880 [label=NativeBatchNormBackward0]
	2504708605120 -> 2504708604880
	2504708605120 [label=ConvolutionBackward0]
	2504708605312 -> 2504708605120
	2504708605312 [label=ReluBackward0]
	2504708605456 -> 2504708605312
	2504708605456 [label=NativeBatchNormBackward0]
	2504708605504 -> 2504708605456
	2504708605504 [label=ConvolutionBackward0]
	2504708605792 -> 2504708605504
	2504708605792 [label=ReluBackward0]
	2504708605936 -> 2504708605792
	2504708605936 [label=NativeBatchNormBackward0]
	2504708605984 -> 2504708605936
	2504708605984 [label=ConvolutionBackward0]
	2504708606272 -> 2504708605984
	2504708606272 [label=ReluBackward0]
	2504708606416 -> 2504708606272
	2504708606416 [label=AddBackward0]
	2504708606464 -> 2504708606416
	2504708606464 [label=NativeBatchNormBackward0]
	2504708606704 -> 2504708606464
	2504708606704 [label=ConvolutionBackward0]
	2504708606896 -> 2504708606704
	2504708606896 [label=ReluBackward0]
	2504708607040 -> 2504708606896
	2504708607040 [label=NativeBatchNormBackward0]
	2504708607088 -> 2504708607040
	2504708607088 [label=ConvolutionBackward0]
	2504708607376 -> 2504708607088
	2504708607376 [label=ReluBackward0]
	2504708607520 -> 2504708607376
	2504708607520 [label=NativeBatchNormBackward0]
	2504708607568 -> 2504708607520
	2504708607568 [label=ConvolutionBackward0]
	2504708606320 -> 2504708607568
	2504708606320 [label=ReluBackward0]
	2504708607952 -> 2504708606320
	2504708607952 [label=AddBackward0]
	2504708616304 -> 2504708607952
	2504708616304 [label=NativeBatchNormBackward0]
	2504708616496 -> 2504708616304
	2504708616496 [label=ConvolutionBackward0]
	2504708616688 -> 2504708616496
	2504708616688 [label=ReluBackward0]
	2504708616832 -> 2504708616688
	2504708616832 [label=NativeBatchNormBackward0]
	2504708616880 -> 2504708616832
	2504708616880 [label=ConvolutionBackward0]
	2504708617168 -> 2504708616880
	2504708617168 [label=ReluBackward0]
	2504708617312 -> 2504708617168
	2504708617312 [label=NativeBatchNormBackward0]
	2504708617360 -> 2504708617312
	2504708617360 [label=ConvolutionBackward0]
	2504708616256 -> 2504708617360
	2504708616256 [label=ReluBackward0]
	2504708617744 -> 2504708616256
	2504708617744 [label=AddBackward0]
	2504708617792 -> 2504708617744
	2504708617792 [label=NativeBatchNormBackward0]
	2504708618032 -> 2504708617792
	2504708618032 [label=ConvolutionBackward0]
	2504708618224 -> 2504708618032
	2504708618224 [label=ReluBackward0]
	2504708618368 -> 2504708618224
	2504708618368 [label=NativeBatchNormBackward0]
	2504708618416 -> 2504708618368
	2504708618416 [label=ConvolutionBackward0]
	2504708618704 -> 2504708618416
	2504708618704 [label=ReluBackward0]
	2504708618848 -> 2504708618704
	2504708618848 [label=NativeBatchNormBackward0]
	2504708618896 -> 2504708618848
	2504708618896 [label=ConvolutionBackward0]
	2504708617552 -> 2504708618896
	2504708617552 [label=ReluBackward0]
	2504708619280 -> 2504708617552
	2504708619280 [label=AddBackward0]
	2504708619328 -> 2504708619280
	2504708619328 [label=NativeBatchNormBackward0]
	2504708619568 -> 2504708619328
	2504708619568 [label=ConvolutionBackward0]
	2504708619760 -> 2504708619568
	2504708619760 [label=ReluBackward0]
	2504708619904 -> 2504708619760
	2504708619904 [label=NativeBatchNormBackward0]
	2504708619952 -> 2504708619904
	2504708619952 [label=ConvolutionBackward0]
	2504708620240 -> 2504708619952
	2504708620240 [label=ReluBackward0]
	2504708636832 -> 2504708620240
	2504708636832 [label=NativeBatchNormBackward0]
	2504708636880 -> 2504708636832
	2504708636880 [label=ConvolutionBackward0]
	2504708637168 -> 2504708636880
	2504708637168 [label=ReluBackward0]
	2504708637312 -> 2504708637168
	2504708637312 [label=AddBackward0]
	2504708637360 -> 2504708637312
	2504708637360 [label=NativeBatchNormBackward0]
	2504708637600 -> 2504708637360
	2504708637600 [label=ConvolutionBackward0]
	2504708637792 -> 2504708637600
	2504708637792 [label=ReluBackward0]
	2504708637936 -> 2504708637792
	2504708637936 [label=NativeBatchNormBackward0]
	2504708637984 -> 2504708637936
	2504708637984 [label=ConvolutionBackward0]
	2504708638272 -> 2504708637984
	2504708638272 [label=ReluBackward0]
	2504708638416 -> 2504708638272
	2504708638416 [label=NativeBatchNormBackward0]
	2504708638464 -> 2504708638416
	2504708638464 [label=ConvolutionBackward0]
	2504708637216 -> 2504708638464
	2504708637216 [label=ReluBackward0]
	2504708638848 -> 2504708637216
	2504708638848 [label=AddBackward0]
	2504708638896 -> 2504708638848
	2504708638896 [label=NativeBatchNormBackward0]
	2504708639136 -> 2504708638896
	2504708639136 [label=ConvolutionBackward0]
	2504708639328 -> 2504708639136
	2504708639328 [label=ReluBackward0]
	2504708639472 -> 2504708639328
	2504708639472 [label=NativeBatchNormBackward0]
	2504708639520 -> 2504708639472
	2504708639520 [label=ConvolutionBackward0]
	2504708639808 -> 2504708639520
	2504708639808 [label=ReluBackward0]
	2504708639952 -> 2504708639808
	2504708639952 [label=NativeBatchNormBackward0]
	2504708640000 -> 2504708639952
	2504708640000 [label=ConvolutionBackward0]
	2504708638656 -> 2504708640000
	2504708638656 [label=ReluBackward0]
	2504708640384 -> 2504708638656
	2504708640384 [label=AddBackward0]
	2504708640432 -> 2504708640384
	2504708640432 [label=NativeBatchNormBackward0]
	2504708640672 -> 2504708640432
	2504708640672 [label=ConvolutionBackward0]
	2504708649120 -> 2504708640672
	2504708649120 [label=ReluBackward0]
	2504708649264 -> 2504708649120
	2504708649264 [label=NativeBatchNormBackward0]
	2504708649312 -> 2504708649264
	2504708649312 [label=ConvolutionBackward0]
	2504708649600 -> 2504708649312
	2504708649600 [label=ReluBackward0]
	2504708649744 -> 2504708649600
	2504708649744 [label=NativeBatchNormBackward0]
	2504708649792 -> 2504708649744
	2504708649792 [label=ConvolutionBackward0]
	2504708650080 -> 2504708649792
	2504708650080 [label=MaxPool2DWithIndicesBackward0]
	2504708650224 -> 2504708650080
	2504708650224 [label=ReluBackward0]
	2504708650272 -> 2504708650224
	2504708650272 [label=NativeBatchNormBackward0]
	2504708650416 -> 2504708650272
	2504708650416 [label=ConvolutionBackward0]
	2504708650704 -> 2504708650416
	2504743070912 [label="encoder.conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2504743070912 -> 2504708650704
	2504708650704 [label=AccumulateGrad]
	2504708650368 -> 2504708650272
	2504743070992 [label="encoder.bn1.weight
 (64)" fillcolor=lightblue]
	2504743070992 -> 2504708650368
	2504708650368 [label=AccumulateGrad]
	2504708650512 -> 2504708650272
	2504743071072 [label="encoder.bn1.bias
 (64)" fillcolor=lightblue]
	2504743071072 -> 2504708650512
	2504708650512 [label=AccumulateGrad]
	2504708650032 -> 2504708649792
	2504743096784 [label="encoder.layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2504743096784 -> 2504708650032
	2504708650032 [label=AccumulateGrad]
	2504708649648 -> 2504708649744
	2504743096864 [label="encoder.layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2504743096864 -> 2504708649648
	2504708649648 [label=AccumulateGrad]
	2504708649888 -> 2504708649744
	2504743096944 [label="encoder.layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2504743096944 -> 2504708649888
	2504708649888 [label=AccumulateGrad]
	2504708649552 -> 2504708649312
	2504743097344 [label="encoder.layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2504743097344 -> 2504708649552
	2504708649552 [label=AccumulateGrad]
	2504708649168 -> 2504708649264
	2504743097424 [label="encoder.layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2504743097424 -> 2504708649168
	2504708649168 [label=AccumulateGrad]
	2504708649408 -> 2504708649264
	2504743097504 [label="encoder.layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2504743097504 -> 2504708649408
	2504708649408 [label=AccumulateGrad]
	2504708649072 -> 2504708640672
	2504743097904 [label="encoder.layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2504743097904 -> 2504708649072
	2504708649072 [label=AccumulateGrad]
	2504708640624 -> 2504708640432
	2504743097984 [label="encoder.layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	2504743097984 -> 2504708640624
	2504708640624 [label=AccumulateGrad]
	2504708640576 -> 2504708640432
	2504743098064 [label="encoder.layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	2504743098064 -> 2504708640576
	2504708640576 [label=AccumulateGrad]
	2504708640192 -> 2504708640384
	2504708640192 [label=NativeBatchNormBackward0]
	2504708640720 -> 2504708640192
	2504708640720 [label=ConvolutionBackward0]
	2504708650080 -> 2504708640720
	2504708649936 -> 2504708640720
	2504743071552 [label="encoder.layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2504743071552 -> 2504708649936
	2504708649936 [label=AccumulateGrad]
	2504708649504 -> 2504708640192
	2504743071632 [label="encoder.layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2504743071632 -> 2504708649504
	2504708649504 [label=AccumulateGrad]
	2504708649024 -> 2504708640192
	2504743096384 [label="encoder.layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2504743096384 -> 2504708649024
	2504708649024 [label=AccumulateGrad]
	2504708640288 -> 2504708640000
	2504743098464 [label="encoder.layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2504743098464 -> 2504708640288
	2504708640288 [label=AccumulateGrad]
	2504708639856 -> 2504708639952
	2504743098544 [label="encoder.layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2504743098544 -> 2504708639856
	2504708639856 [label=AccumulateGrad]
	2504708640096 -> 2504708639952
	2504743098624 [label="encoder.layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2504743098624 -> 2504708640096
	2504708640096 [label=AccumulateGrad]
	2504708639760 -> 2504708639520
	2504743099024 [label="encoder.layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2504743099024 -> 2504708639760
	2504708639760 [label=AccumulateGrad]
	2504708639376 -> 2504708639472
	2504743099104 [label="encoder.layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2504743099104 -> 2504708639376
	2504708639376 [label=AccumulateGrad]
	2504708639616 -> 2504708639472
	2504743099184 [label="encoder.layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2504743099184 -> 2504708639616
	2504708639616 [label=AccumulateGrad]
	2504708639280 -> 2504708639136
	2504743099584 [label="encoder.layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2504743099584 -> 2504708639280
	2504708639280 [label=AccumulateGrad]
	2504708639088 -> 2504708638896
	2504743099664 [label="encoder.layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	2504743099664 -> 2504708639088
	2504708639088 [label=AccumulateGrad]
	2504708639040 -> 2504708638896
	2504743099744 [label="encoder.layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	2504743099744 -> 2504708639040
	2504708639040 [label=AccumulateGrad]
	2504708638656 -> 2504708638848
	2504708638752 -> 2504708638464
	2504743100144 [label="encoder.layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2504743100144 -> 2504708638752
	2504708638752 [label=AccumulateGrad]
	2504708638320 -> 2504708638416
	2504743100224 [label="encoder.layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	2504743100224 -> 2504708638320
	2504708638320 [label=AccumulateGrad]
	2504708638560 -> 2504708638416
	2504743100304 [label="encoder.layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	2504743100304 -> 2504708638560
	2504708638560 [label=AccumulateGrad]
	2504708638224 -> 2504708637984
	2504743174528 [label="encoder.layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2504743174528 -> 2504708638224
	2504708638224 [label=AccumulateGrad]
	2504708637840 -> 2504708637936
	2504743174608 [label="encoder.layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	2504743174608 -> 2504708637840
	2504708637840 [label=AccumulateGrad]
	2504708638080 -> 2504708637936
	2504743174688 [label="encoder.layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	2504743174688 -> 2504708638080
	2504708638080 [label=AccumulateGrad]
	2504708637744 -> 2504708637600
	2504743175088 [label="encoder.layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	2504743175088 -> 2504708637744
	2504708637744 [label=AccumulateGrad]
	2504708637552 -> 2504708637360
	2504743175168 [label="encoder.layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	2504743175168 -> 2504708637552
	2504708637552 [label=AccumulateGrad]
	2504708637504 -> 2504708637360
	2504743175248 [label="encoder.layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	2504743175248 -> 2504708637504
	2504708637504 [label=AccumulateGrad]
	2504708637216 -> 2504708637312
	2504708637120 -> 2504708636880
	2504743176208 [label="encoder.layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2504743176208 -> 2504708637120
	2504708637120 [label=AccumulateGrad]
	2504708636736 -> 2504708636832
	2504743176288 [label="encoder.layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2504743176288 -> 2504708636736
	2504708636736 [label=AccumulateGrad]
	2504708636976 -> 2504708636832
	2504743176368 [label="encoder.layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2504743176368 -> 2504708636976
	2504708636976 [label=AccumulateGrad]
	2504708620192 -> 2504708619952
	2504743176768 [label="encoder.layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2504743176768 -> 2504708620192
	2504708620192 [label=AccumulateGrad]
	2504708619808 -> 2504708619904
	2504743176848 [label="encoder.layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2504743176848 -> 2504708619808
	2504708619808 [label=AccumulateGrad]
	2504708620048 -> 2504708619904
	2504743176928 [label="encoder.layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2504743176928 -> 2504708620048
	2504708620048 [label=AccumulateGrad]
	2504708619712 -> 2504708619568
	2504743177328 [label="encoder.layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2504743177328 -> 2504708619712
	2504708619712 [label=AccumulateGrad]
	2504708619520 -> 2504708619328
	2504743177408 [label="encoder.layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	2504743177408 -> 2504708619520
	2504708619520 [label=AccumulateGrad]
	2504708619472 -> 2504708619328
	2504743177488 [label="encoder.layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	2504743177488 -> 2504708619472
	2504708619472 [label=AccumulateGrad]
	2504708619088 -> 2504708619280
	2504708619088 [label=NativeBatchNormBackward0]
	2504708620144 -> 2504708619088
	2504708620144 [label=ConvolutionBackward0]
	2504708637168 -> 2504708620144
	2504708619856 -> 2504708620144
	2504743175648 [label="encoder.layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2504743175648 -> 2504708619856
	2504708619856 [label=AccumulateGrad]
	2504708619664 -> 2504708619088
	2504743175728 [label="encoder.layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2504743175728 -> 2504708619664
	2504708619664 [label=AccumulateGrad]
	2504708619616 -> 2504708619088
	2504743175808 [label="encoder.layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2504743175808 -> 2504708619616
	2504708619616 [label=AccumulateGrad]
	2504708619184 -> 2504708618896
	2504743177888 [label="encoder.layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2504743177888 -> 2504708619184
	2504708619184 [label=AccumulateGrad]
	2504708618752 -> 2504708618848
	2504743177968 [label="encoder.layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2504743177968 -> 2504708618752
	2504708618752 [label=AccumulateGrad]
	2504708618992 -> 2504708618848
	2504743178048 [label="encoder.layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2504743178048 -> 2504708618992
	2504708618992 [label=AccumulateGrad]
	2504708618656 -> 2504708618416
	2504743252272 [label="encoder.layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2504743252272 -> 2504708618656
	2504708618656 [label=AccumulateGrad]
	2504708618272 -> 2504708618368
	2504743252352 [label="encoder.layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2504743252352 -> 2504708618272
	2504708618272 [label=AccumulateGrad]
	2504708618512 -> 2504708618368
	2504743252432 [label="encoder.layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2504743252432 -> 2504708618512
	2504708618512 [label=AccumulateGrad]
	2504708618176 -> 2504708618032
	2504743252832 [label="encoder.layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2504743252832 -> 2504708618176
	2504708618176 [label=AccumulateGrad]
	2504708617984 -> 2504708617792
	2504743252912 [label="encoder.layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	2504743252912 -> 2504708617984
	2504708617984 [label=AccumulateGrad]
	2504708617936 -> 2504708617792
	2504743252992 [label="encoder.layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	2504743252992 -> 2504708617936
	2504708617936 [label=AccumulateGrad]
	2504708617552 -> 2504708617744
	2504708617648 -> 2504708617360
	2504743253392 [label="encoder.layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2504743253392 -> 2504708617648
	2504708617648 [label=AccumulateGrad]
	2504708617216 -> 2504708617312
	2504743253472 [label="encoder.layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	2504743253472 -> 2504708617216
	2504708617216 [label=AccumulateGrad]
	2504708617456 -> 2504708617312
	2504743253552 [label="encoder.layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	2504743253552 -> 2504708617456
	2504708617456 [label=AccumulateGrad]
	2504708617120 -> 2504708616880
	2504743253952 [label="encoder.layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2504743253952 -> 2504708617120
	2504708617120 [label=AccumulateGrad]
	2504708616736 -> 2504708616832
	2504743254032 [label="encoder.layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	2504743254032 -> 2504708616736
	2504708616736 [label=AccumulateGrad]
	2504708616976 -> 2504708616832
	2504743254112 [label="encoder.layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	2504743254112 -> 2504708616976
	2504708616976 [label=AccumulateGrad]
	2504708616640 -> 2504708616496
	2504743254512 [label="encoder.layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2504743254512 -> 2504708616640
	2504708616640 [label=AccumulateGrad]
	2504708616448 -> 2504708616304
	2504743254592 [label="encoder.layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	2504743254592 -> 2504708616448
	2504708616448 [label=AccumulateGrad]
	2504708616400 -> 2504708616304
	2504743254672 [label="encoder.layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	2504743254672 -> 2504708616400
	2504708616400 [label=AccumulateGrad]
	2504708616256 -> 2504708607952
	2504708607856 -> 2504708607568
	2504743255072 [label="encoder.layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2504743255072 -> 2504708607856
	2504708607856 [label=AccumulateGrad]
	2504708607424 -> 2504708607520
	2504743255152 [label="encoder.layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	2504743255152 -> 2504708607424
	2504708607424 [label=AccumulateGrad]
	2504708607664 -> 2504708607520
	2504743255232 [label="encoder.layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	2504743255232 -> 2504708607664
	2504708607664 [label=AccumulateGrad]
	2504708607328 -> 2504708607088
	2504743255632 [label="encoder.layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2504743255632 -> 2504708607328
	2504708607328 [label=AccumulateGrad]
	2504708606944 -> 2504708607040
	2504743255712 [label="encoder.layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	2504743255712 -> 2504708606944
	2504708606944 [label=AccumulateGrad]
	2504708607184 -> 2504708607040
	2504743255792 [label="encoder.layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	2504743255792 -> 2504708607184
	2504708607184 [label=AccumulateGrad]
	2504708606848 -> 2504708606704
	2504743330016 [label="encoder.layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	2504743330016 -> 2504708606848
	2504708606848 [label=AccumulateGrad]
	2504708606656 -> 2504708606464
	2504743330096 [label="encoder.layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	2504743330096 -> 2504708606656
	2504708606656 [label=AccumulateGrad]
	2504708606608 -> 2504708606464
	2504743330176 [label="encoder.layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	2504743330176 -> 2504708606608
	2504708606608 [label=AccumulateGrad]
	2504708606320 -> 2504708606416
	2504708606224 -> 2504708605984
	2504743331136 [label="encoder.layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2504743331136 -> 2504708606224
	2504708606224 [label=AccumulateGrad]
	2504708605840 -> 2504708605936
	2504743331216 [label="encoder.layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2504743331216 -> 2504708605840
	2504708605840 [label=AccumulateGrad]
	2504708606080 -> 2504708605936
	2504743331296 [label="encoder.layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2504743331296 -> 2504708606080
	2504708606080 [label=AccumulateGrad]
	2504708605744 -> 2504708605504
	2504743331696 [label="encoder.layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504743331696 -> 2504708605744
	2504708605744 [label=AccumulateGrad]
	2504708605360 -> 2504708605456
	2504743331776 [label="encoder.layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2504743331776 -> 2504708605360
	2504708605360 [label=AccumulateGrad]
	2504708605600 -> 2504708605456
	2504743331856 [label="encoder.layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2504743331856 -> 2504708605600
	2504708605600 [label=AccumulateGrad]
	2504708605264 -> 2504708605120
	2504743332256 [label="encoder.layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504743332256 -> 2504708605264
	2504708605264 [label=AccumulateGrad]
	2504708605072 -> 2504708604880
	2504743332336 [label="encoder.layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	2504743332336 -> 2504708605072
	2504708605072 [label=AccumulateGrad]
	2504708605024 -> 2504708604880
	2504743332416 [label="encoder.layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	2504743332416 -> 2504708605024
	2504708605024 [label=AccumulateGrad]
	2504708604640 -> 2504708604832
	2504708604640 [label=NativeBatchNormBackward0]
	2504708605696 -> 2504708604640
	2504708605696 [label=ConvolutionBackward0]
	2504708606272 -> 2504708605696
	2504708606128 -> 2504708605696
	2504743330576 [label="encoder.layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	2504743330576 -> 2504708606128
	2504708606128 [label=AccumulateGrad]
	2504708605216 -> 2504708604640
	2504743330656 [label="encoder.layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	2504743330656 -> 2504708605216
	2504708605216 [label=AccumulateGrad]
	2504708605168 -> 2504708604640
	2504743330736 [label="encoder.layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	2504743330736 -> 2504708605168
	2504708605168 [label=AccumulateGrad]
	2504708604736 -> 2504708604448
	2504743332816 [label="encoder.layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2504743332816 -> 2504708604736
	2504708604736 [label=AccumulateGrad]
	2504708604304 -> 2504708604400
	2504743332896 [label="encoder.layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2504743332896 -> 2504708604304
	2504708604304 [label=AccumulateGrad]
	2504708604544 -> 2504708604400
	2504743332976 [label="encoder.layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2504743332976 -> 2504708604544
	2504708604544 [label=AccumulateGrad]
	2504708604208 -> 2504708604016
	2504743333376 [label="encoder.layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504743333376 -> 2504708604208
	2504708604208 [label=AccumulateGrad]
	2504708603968 -> 2504708595664
	2504743333456 [label="encoder.layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2504743333456 -> 2504708603968
	2504708603968 [label=AccumulateGrad]
	2504708604064 -> 2504708595664
	2504743333536 [label="encoder.layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2504743333536 -> 2504708604064
	2504708604064 [label=AccumulateGrad]
	2504708595472 -> 2504708595328
	2504749109392 [label="encoder.layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504749109392 -> 2504708595472
	2504708595472 [label=AccumulateGrad]
	2504708595280 -> 2504708595088
	2504749109472 [label="encoder.layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	2504749109472 -> 2504708595280
	2504708595280 [label=AccumulateGrad]
	2504708595232 -> 2504708595088
	2504749109552 [label="encoder.layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	2504749109552 -> 2504708595232
	2504708595232 [label=AccumulateGrad]
	2504708594848 -> 2504708595040
	2504708594944 -> 2504708594656
	2504749109952 [label="encoder.layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2504749109952 -> 2504708594944
	2504708594944 [label=AccumulateGrad]
	2504708594512 -> 2504708594608
	2504749110032 [label="encoder.layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	2504749110032 -> 2504708594512
	2504708594512 [label=AccumulateGrad]
	2504708594752 -> 2504708594608
	2504749110112 [label="encoder.layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	2504749110112 -> 2504708594752
	2504708594752 [label=AccumulateGrad]
	2504708594416 -> 2504708594176
	2504749110512 [label="encoder.layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504749110512 -> 2504708594416
	2504708594416 [label=AccumulateGrad]
	2504708594032 -> 2504708594128
	2504749110592 [label="encoder.layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	2504749110592 -> 2504708594032
	2504708594032 [label=AccumulateGrad]
	2504708594272 -> 2504708594128
	2504749110672 [label="encoder.layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	2504749110672 -> 2504708594272
	2504708594272 [label=AccumulateGrad]
	2504708593936 -> 2504708593792
	2504749111072 [label="encoder.layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504749111072 -> 2504708593936
	2504708593936 [label=AccumulateGrad]
	2504708593744 -> 2504708593552
	2504749111152 [label="encoder.layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	2504749111152 -> 2504708593744
	2504708593744 [label=AccumulateGrad]
	2504708593696 -> 2504708593552
	2504749111232 [label="encoder.layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	2504749111232 -> 2504708593696
	2504708593696 [label=AccumulateGrad]
	2504708593312 -> 2504708593504
	2504708593408 -> 2504708593120
	2504749111632 [label="encoder.layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2504749111632 -> 2504708593408
	2504708593408 [label=AccumulateGrad]
	2504708592976 -> 2504708593072
	2504749111712 [label="encoder.layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	2504749111712 -> 2504708592976
	2504708592976 [label=AccumulateGrad]
	2504708593216 -> 2504708593072
	2504749111792 [label="encoder.layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	2504749111792 -> 2504708593216
	2504708593216 [label=AccumulateGrad]
	2504708592880 -> 2504708592640
	2504749112192 [label="encoder.layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504749112192 -> 2504708592880
	2504708592880 [label=AccumulateGrad]
	2504708592496 -> 2504708592592
	2504749112272 [label="encoder.layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	2504749112272 -> 2504708592496
	2504708592496 [label=AccumulateGrad]
	2504708592736 -> 2504708592592
	2504749112352 [label="encoder.layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	2504749112352 -> 2504708592736
	2504708592736 [label=AccumulateGrad]
	2504708592400 -> 2504708592256
	2504749112752 [label="encoder.layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504749112752 -> 2504708592400
	2504708592400 [label=AccumulateGrad]
	2504708592208 -> 2504708592016
	2504749112832 [label="encoder.layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	2504749112832 -> 2504708592208
	2504708592208 [label=AccumulateGrad]
	2504708592160 -> 2504708592016
	2504749112912 [label="encoder.layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	2504749112912 -> 2504708592160
	2504708592160 [label=AccumulateGrad]
	2504708591776 -> 2504708591968
	2504708591872 -> 2504708579280
	2504749178944 [label="encoder.layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2504749178944 -> 2504708591872
	2504708591872 [label=AccumulateGrad]
	2504708579136 -> 2504708579232
	2504749179024 [label="encoder.layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	2504749179024 -> 2504708579136
	2504708579136 [label=AccumulateGrad]
	2504708591680 -> 2504708579232
	2504749179104 [label="encoder.layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	2504749179104 -> 2504708591680
	2504708591680 [label=AccumulateGrad]
	2504708579040 -> 2504708578896
	2504749179504 [label="encoder.layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504749179504 -> 2504708579040
	2504708579040 [label=AccumulateGrad]
	2504708578848 -> 2504708578800
	2504749179584 [label="encoder.layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	2504749179584 -> 2504708578848
	2504708578848 [label=AccumulateGrad]
	2504708578704 -> 2504708578800
	2504749179664 [label="encoder.layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	2504749179664 -> 2504708578704
	2504708578704 [label=AccumulateGrad]
	2504708578608 -> 2504708578464
	2504749180064 [label="encoder.layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504749180064 -> 2504708578608
	2504708578608 [label=AccumulateGrad]
	2504708578416 -> 2504708578320
	2504749180144 [label="encoder.layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	2504749180144 -> 2504708578416
	2504708578416 [label=AccumulateGrad]
	2504708578368 -> 2504708578320
	2504749180224 [label="encoder.layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	2504749180224 -> 2504708578368
	2504708578368 [label=AccumulateGrad]
	2504708578272 -> 2504708578224
	2504708578128 -> 2504708577936
	2504749180624 [label="encoder.layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	2504749180624 -> 2504708578128
	2504708578128 [label=AccumulateGrad]
	2504708577888 -> 2504708577840
	2504749180704 [label="encoder.layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	2504749180704 -> 2504708577888
	2504708577888 [label=AccumulateGrad]
	2504708577744 -> 2504708577840
	2504749180784 [label="encoder.layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	2504749180784 -> 2504708577744
	2504708577744 [label=AccumulateGrad]
	2504708577648 -> 2504708577504
	2504749181184 [label="encoder.layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2504749181184 -> 2504708577648
	2504708577648 [label=AccumulateGrad]
	2504708577456 -> 2504708577408
	2504749181264 [label="encoder.layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	2504749181264 -> 2504708577456
	2504708577456 [label=AccumulateGrad]
	2504708577312 -> 2504708577408
	2504749181344 [label="encoder.layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	2504749181344 -> 2504708577312
	2504708577312 [label=AccumulateGrad]
	2504708577216 -> 2504708577072
	2504749181744 [label="encoder.layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	2504749181744 -> 2504708577216
	2504708577216 [label=AccumulateGrad]
	2504708577024 -> 2504708576928
	2504749181824 [label="encoder.layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	2504749181824 -> 2504708577024
	2504708577024 [label=AccumulateGrad]
	2504708576976 -> 2504708576928
	2504749181904 [label="encoder.layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	2504749181904 -> 2504708576976
	2504708576976 [label=AccumulateGrad]
	2504708576880 -> 2504708576832
	2504708576640 -> 2504708576496
	2504749182864 [label="encoder.layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2504749182864 -> 2504708576640
	2504708576640 [label=AccumulateGrad]
	2504708576448 -> 2504708576400
	2504749273152 [label="encoder.layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2504749273152 -> 2504708576448
	2504708576448 [label=AccumulateGrad]
	2504708576304 -> 2504708576400
	2504749273232 [label="encoder.layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2504749273232 -> 2504708576304
	2504708576304 [label=AccumulateGrad]
	2504708576208 -> 2504708576064
	2504749273632 [label="encoder.layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2504749273632 -> 2504708576208
	2504708576208 [label=AccumulateGrad]
	2504708576016 -> 2504708575968
	2504749273712 [label="encoder.layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2504749273712 -> 2504708576016
	2504708576016 [label=AccumulateGrad]
	2504708575872 -> 2504708575968
	2504749273792 [label="encoder.layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2504749273792 -> 2504708575872
	2504708575872 [label=AccumulateGrad]
	2504708575776 -> 2504708575632
	2504749274192 [label="encoder.layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2504749274192 -> 2504708575776
	2504708575776 [label=AccumulateGrad]
	2504708575584 -> 2504708575488
	2504749274272 [label="encoder.layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	2504749274272 -> 2504708575584
	2504708575584 [label=AccumulateGrad]
	2504708575536 -> 2504708575488
	2504749274352 [label="encoder.layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	2504749274352 -> 2504708575536
	2504708575536 [label=AccumulateGrad]
	2504708575440 -> 2504708575392
	2504708575440 [label=NativeBatchNormBackward0]
	2504708576160 -> 2504708575440
	2504708576160 [label=ConvolutionBackward0]
	2504708576688 -> 2504708576160
	2504708576544 -> 2504708576160
	2504749182304 [label="encoder.layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	2504749182304 -> 2504708576544
	2504708576544 [label=AccumulateGrad]
	2504708575728 -> 2504708575440
	2504749182384 [label="encoder.layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	2504749182384 -> 2504708575728
	2504708575728 [label=AccumulateGrad]
	2504708575680 -> 2504708575440
	2504749182464 [label="encoder.layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	2504749182464 -> 2504708575680
	2504708575680 [label=AccumulateGrad]
	2504708566992 -> 2504708566848
	2504749274752 [label="encoder.layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2504749274752 -> 2504708566992
	2504708566992 [label=AccumulateGrad]
	2504708566800 -> 2504708566752
	2504749274832 [label="encoder.layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2504749274832 -> 2504708566800
	2504708566800 [label=AccumulateGrad]
	2504708566656 -> 2504708566752
	2504749274912 [label="encoder.layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2504749274912 -> 2504708566656
	2504708566656 [label=AccumulateGrad]
	2504708566560 -> 2504708566416
	2504749275312 [label="encoder.layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2504749275312 -> 2504708566560
	2504708566560 [label=AccumulateGrad]
	2504708566368 -> 2504708566320
	2504749275392 [label="encoder.layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2504749275392 -> 2504708566368
	2504708566368 [label=AccumulateGrad]
	2504708566224 -> 2504708566320
	2504749275472 [label="encoder.layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2504749275472 -> 2504708566224
	2504708566224 [label=AccumulateGrad]
	2504708566128 -> 2504708565984
	2504749275872 [label="encoder.layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2504749275872 -> 2504708566128
	2504708566128 [label=AccumulateGrad]
	2504708565936 -> 2504708565840
	2504749275952 [label="encoder.layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	2504749275952 -> 2504708565936
	2504708565936 [label=AccumulateGrad]
	2504708565888 -> 2504708565840
	2504749276032 [label="encoder.layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	2504749276032 -> 2504708565888
	2504708565888 [label=AccumulateGrad]
	2504708565792 -> 2504708565744
	2504708565648 -> 2504708565456
	2504749276432 [label="encoder.layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	2504749276432 -> 2504708565648
	2504708565648 [label=AccumulateGrad]
	2504708565408 -> 2504708565360
	2504749276512 [label="encoder.layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	2504749276512 -> 2504708565408
	2504708565408 [label=AccumulateGrad]
	2504708565264 -> 2504708565360
	2504749276592 [label="encoder.layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	2504749276592 -> 2504708565264
	2504708565264 [label=AccumulateGrad]
	2504708565168 -> 2504708565024
	2504749276992 [label="encoder.layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2504749276992 -> 2504708565168
	2504708565168 [label=AccumulateGrad]
	2504708564976 -> 2504708564928
	2504749277072 [label="encoder.layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	2504749277072 -> 2504708564976
	2504708564976 [label=AccumulateGrad]
	2504708564832 -> 2504708564928
	2504749334592 [label="encoder.layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	2504749334592 -> 2504708564832
	2504708564832 [label=AccumulateGrad]
	2504708564736 -> 2504708564592
	2504749334992 [label="encoder.layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	2504749334992 -> 2504708564736
	2504708564736 [label=AccumulateGrad]
	2504708564544 -> 2504708564448
	2504749335072 [label="encoder.layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	2504749335072 -> 2504708564544
	2504708564544 [label=AccumulateGrad]
	2504708564496 -> 2504708564448
	2504749335152 [label="encoder.layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	2504749335152 -> 2504708564496
	2504708564496 [label=AccumulateGrad]
	2504708564400 -> 2504708564352
	2504708563056 -> 2504708563728
	2504708563056 [label=AddBackward0]
	2504708564304 -> 2504708563056
	2504708564304 [label=AddmmBackward0]
	2504708563200 -> 2504708564304
	2504708564688 -> 2504708564304
	2504708564688 [label=MulBackward0]
	2504708564880 -> 2504708564688
	2504708564880 [label=AddmmBackward0]
	2504708563488 -> 2504708564880
	2504708565504 -> 2504708564880
	2504708565504 [label=MulBackward0]
	2504708565696 -> 2504708565504
	2504708565696 [label=AddmmBackward0]
	2504708563776 -> 2504708565696
	2504708566512 -> 2504708565696
	2504708566512 [label=CatBackward0]
	2504708563872 -> 2504708566512
	2504708564208 -> 2504708566512
	2504708564208 [label=AddBackward0]
	2504708566704 -> 2504708564208
	2504708566704 [label=AddmmBackward0]
	2504708563200 -> 2504708566704
	2504708575344 -> 2504708566704
	2504708575344 [label=MulBackward0]
	2504708576352 -> 2504708575344
	2504708576352 [label=AddmmBackward0]
	2504708563488 -> 2504708576352
	2504708576736 -> 2504708576352
	2504708576736 [label=MulBackward0]
	2504708577600 -> 2504708576736
	2504708577600 [label=AddmmBackward0]
	2504708563776 -> 2504708577600
	2504708577360 -> 2504708577600
	2504708577360 [label=CatBackward0]
	2504708563872 -> 2504708577360
	2504708577552 -> 2504708577600
	2504708577552 [label=TBackward0]
	2504708578080 -> 2504708577552
	2504749335472 [label="fc1.weight
 (1024, 2208)" fillcolor=lightblue]
	2504749335472 -> 2504708578080
	2504708578080 [label=AccumulateGrad]
	2504708575920 -> 2504708576352
	2504708575920 [label=TBackward0]
	2504708577984 -> 2504708575920
	2504749335632 [label="fc2.weight
 (1024, 1024)" fillcolor=lightblue]
	2504749335632 -> 2504708577984
	2504708577984 [label=AccumulateGrad]
	2504708575296 -> 2504708566704
	2504708575296 [label=TBackward0]
	2504708576784 -> 2504708575296
	2504749335792 [label="decpose.weight
 (144, 1024)" fillcolor=lightblue]
	2504749335792 -> 2504708576784
	2504708576784 [label=AccumulateGrad]
	2504708566944 -> 2504708566512
	2504708566944 [label=AddBackward0]
	2504708566896 -> 2504708566944
	2504708566896 [label=AddmmBackward0]
	2504708578512 -> 2504708566896
	2504749336032 [label="decshape.bias
 (10)" fillcolor=lightblue]
	2504749336032 -> 2504708578512
	2504708578512 [label=AccumulateGrad]
	2504708575344 -> 2504708566896
	2504708578032 -> 2504708566896
	2504708578032 [label=TBackward0]
	2504708577120 -> 2504708578032
	2504749335952 [label="decshape.weight
 (10, 1024)" fillcolor=lightblue]
	2504749335952 -> 2504708577120
	2504708577120 [label=AccumulateGrad]
	2504708566272 -> 2504708566512
	2504708566272 [label=AddBackward0]
	2504708577168 -> 2504708566272
	2504708577168 [label=AddmmBackward0]
	2504708578176 -> 2504708577168
	2504749336192 [label="deccam.bias
 (3)" fillcolor=lightblue]
	2504749336192 -> 2504708578176
	2504708578176 [label=AccumulateGrad]
	2504708575344 -> 2504708577168
	2504708578560 -> 2504708577168
	2504708578560 [label=TBackward0]
	2504708577792 -> 2504708578560
	2504749336112 [label="deccam.weight
 (3, 1024)" fillcolor=lightblue]
	2504749336112 -> 2504708577792
	2504708577792 [label=AccumulateGrad]
	2504708566080 -> 2504708565696
	2504708566080 [label=TBackward0]
	2504708578080 -> 2504708566080
	2504708566032 -> 2504708564880
	2504708566032 [label=TBackward0]
	2504708577984 -> 2504708566032
	2504708564640 -> 2504708564304
	2504708564640 [label=TBackward0]
	2504708576784 -> 2504708564640
	2504708564208 -> 2504708563056
	2504708563920 -> 2504708563728
	2504708563920 [label=AddBackward0]
	2504708566464 -> 2504708563920
	2504708566464 [label=AddmmBackward0]
	2504708578512 -> 2504708566464
	2504708564688 -> 2504708566464
	2504708565072 -> 2504708566464
	2504708565072 [label=TBackward0]
	2504708577120 -> 2504708565072
	2504708566944 -> 2504708563920
	2504708563968 -> 2504708563728
	2504708563968 [label=AddBackward0]
	2504708565552 -> 2504708563968
	2504708565552 [label=AddmmBackward0]
	2504708578176 -> 2504708565552
	2504708564688 -> 2504708565552
	2504708564112 -> 2504708565552
	2504708564112 [label=TBackward0]
	2504708577792 -> 2504708564112
	2504708566272 -> 2504708563968
	2504708563680 -> 2504708563584
	2504708563680 [label=TBackward0]
	2504708578080 -> 2504708563680
	2504708563392 -> 2504708563296
	2504708563392 [label=TBackward0]
	2504708577984 -> 2504708563392
	2504708563104 -> 2504708488544
	2504708563104 [label=TBackward0]
	2504708576784 -> 2504708563104
	2504708563056 -> 2504869875040
	2504708488640 -> 2504708489072
	2504708488640 [label=ExpandBackward0]
	2504708488160 -> 2504708488640
	2504708488160 [label=ClampMinBackward0]
	2504708488064 -> 2504708488160
	2504708488064 [label=NormBackward1]
	2504708488592 -> 2504708488064
	2504708488688 -> 2504708488736
	2504708488688 [label=DivBackward0]
	2504708488400 -> 2504708488688
	2504708488400 [label=SubBackward0]
	2504708563008 -> 2504708488400
	2504708563008 [label=SelectBackward0]
	2504708563824 -> 2504708563008
	2504708563824 [label=SliceBackward0]
	2504708565120 -> 2504708563824
	2504708565120 [label=SliceBackward0]
	2504708488112 -> 2504708565120
	2504708563248 -> 2504708488400
	2504708563248 [label=MulBackward0]
	2504708564064 -> 2504708563248
	2504708564064 [label=UnsqueezeBackward0]
	2504708563536 -> 2504708564064
	2504708563536 [label=ViewBackward0]
	2504708563344 -> 2504708563536
	2504708563344 [label=PermuteBackward0]
	2504708579184 -> 2504708563344
	2504708579184 [label=ViewBackward0]
	2504708578944 -> 2504708579184
	2504708578944 [label=BmmBackward0]
	2504708576112 -> 2504708578944
	2504708576112 [label=ReshapeAliasBackward0]
	2504708591920 -> 2504708576112
	2504708591920 [label=PermuteBackward0]
	2504708592832 -> 2504708591920
	2504708592832 [label=PermuteBackward0]
	2504708489072 -> 2504708592832
	2504708591728 -> 2504708578944
	2504708591728 [label=ReshapeAliasBackward0]
	2504708592544 -> 2504708591728
	2504708592544 [label=PermuteBackward0]
	2504708592304 -> 2504708592544
	2504708592304 [label=PermuteBackward0]
	2504708563008 -> 2504708592304
	2504708489072 -> 2504708563248
	2504708488304 -> 2504708488688
	2504708488304 [label=ExpandBackward0]
	2504708564016 -> 2504708488304
	2504708564016 [label=ClampMinBackward0]
	2504708565312 -> 2504708564016
	2504708565312 [label=NormBackward1]
	2504708488400 -> 2504708565312
	2504708488784 -> 2504708488736
	2504708488784 [label=LinalgCrossBackward0]
	2504708489072 -> 2504708488784
	2504708488688 -> 2504708488784
	2504708489168 -> 2504708533920
	2504708534000 [label="
 (24, 3, 3)" fillcolor=darkolivegreen3]
	2504708488736 -> 2504708534000
	2504708534000 -> 2504708533920 [style=dotted]
	2504708532320 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2504708563632 [label=AddBackward0]
	2504708488976 -> 2504708563632
	2504708488976 [label=AddmmBackward0]
	2504708578512 -> 2504708488976
	2504708563152 -> 2504708488976
	2504708488832 -> 2504708488976
	2504708488832 [label=TBackward0]
	2504708577120 -> 2504708488832
	2504708563920 -> 2504708563632
	2504708563632 -> 2504708532320
	2504708532720 [label="
 (1, 3)" fillcolor=darkolivegreen1]
	2504708489120 [label=AddBackward0]
	2504708578992 -> 2504708489120
	2504708578992 [label=AddmmBackward0]
	2504708578176 -> 2504708578992
	2504708563152 -> 2504708578992
	2504708578752 -> 2504708578992
	2504708578752 [label=TBackward0]
	2504708577792 -> 2504708578752
	2504708563968 -> 2504708489120
	2504708489120 -> 2504708532720
}
